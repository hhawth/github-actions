#!/usr/bin/env python3
"""
Database sync utility for Cloud Run
- Downloads database from GCS on startup
- Periodically uploads local changes back to GCS
"""
import os
import subprocess
import time
import threading
from pathlib import Path
from datetime import datetime

DB_FILE = "football_data.duckdb"
PROJECT_ID = os.getenv("GOOGLE_CLOUD_PROJECT") or os.getenv("GOOGLE_PROJECT")
BUCKET_NAME = os.getenv("GOOGLE_BUCKET") or (f"{PROJECT_ID}-bucket" if PROJECT_ID else None)
GCS_PATH = f"gs://{BUCKET_NAME}/{DB_FILE}" if BUCKET_NAME else None

# Debug environment variables
print(f"ðŸ”§ Debug: GOOGLE_PROJECT={PROJECT_ID}")
print(f"ðŸ”§ Debug: GOOGLE_BUCKET={BUCKET_NAME}")
print(f"ðŸ”§ Debug: GCS_PATH={GCS_PATH}")

# Sync interval (seconds)
SYNC_INTERVAL = 3600  # 1 hour

def run_gsutil_command(cmd):
    """Run gsutil command with error handling"""
    print(f"ðŸ”§ Debug: Running command: {' '.join(cmd)}")
    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=120
        )
        print(f"ðŸ”§ Debug: Command exit code: {result.returncode}")
        if result.stdout:
            print(f"ðŸ”§ Debug: Stdout: {result.stdout[:200]}...")
        if result.stderr:
            print(f"ðŸ”§ Debug: Stderr: {result.stderr[:200]}...")
        return result.returncode == 0, result.stdout, result.stderr
    except subprocess.TimeoutExpired:
        print("âŒ Debug: Command timed out")
        return False, "", "Command timed out"
    except FileNotFoundError as e:
        print(f"âŒ Debug: gsutil not found: {e}")
        return False, "", "gsutil not found"
    except Exception as e:
        print(f"âŒ Debug: Command failed: {e}")
        return False, "", str(e)

def download_from_gcs():
    """Download database from GCS to local"""
    print("ðŸ”§ Debug: Attempting GCS download...")
    print(f"ðŸ”§ Debug: GCS_PATH = {GCS_PATH}")
    print(f"ðŸ”§ Debug: BUCKET_NAME = {BUCKET_NAME}")
    print(f"ðŸ”§ Debug: DB_FILE = {DB_FILE}")
    print(f"ðŸ”§ Debug: Current working directory: {os.getcwd()}")
    
    if not GCS_PATH:
        print("âŒ No GOOGLE_CLOUD_PROJECT or GOOGLE_BUCKET set, skipping GCS download")
        print(f"ðŸ”§ Debug: PROJECT_ID={PROJECT_ID}, BUCKET_NAME={BUCKET_NAME}")
        return False
    
    db_file = Path(DB_FILE)
    
    # Check if database already exists locally and remove it to force fresh download
    if db_file.exists():
        size_mb = db_file.stat().st_size / (1024 * 1024)
        print(f"ðŸ”§ Debug: Local database exists ({size_mb:.1f} MB), removing for fresh download")
        try:
            db_file.unlink()
            print("ðŸ”§ Debug: Removed existing local database")
        except Exception as e:
            print(f"âŒ Failed to remove existing database: {e}")
            return False
    
    print(f"ðŸ“¥ Starting download from {GCS_PATH}...")
    
    # Try to test gsutil first
    test_success, test_stdout, test_stderr = run_gsutil_command(["gsutil", "version"])
    if not test_success:
        print(f"âŒ gsutil not available: {test_stderr}")
        return False
        
    print(f"âœ… gsutil is available: {test_stdout[:100]}...")
    
    # Check if file exists in GCS first
    print("ðŸ”§ Debug: Checking if file exists in GCS...")
    ls_success, ls_stdout, ls_stderr = run_gsutil_command(["gsutil", "ls", "-l", GCS_PATH])
    if ls_success:
        print(f"ðŸ”§ Debug: GCS file info: {ls_stdout.strip()}")
    else:
        print(f"âŒ File not found in GCS: {ls_stderr}")
        return False
    
    # Download with progress
    success, stdout, stderr = run_gsutil_command(["gsutil", "-m", "cp", GCS_PATH, DB_FILE])
    
    if success:
        print("ðŸ”§ Debug: Download command succeeded")
        if db_file.exists():
            size_mb = db_file.stat().st_size / (1024 * 1024)
            print(f"âœ… Database downloaded successfully ({size_mb:.1f} MB)")
            
            # Verify the downloaded database  
            try:
                import duckdb
                conn = duckdb.connect(str(db_file))
                tables = conn.execute("SHOW TABLES").fetchall()
                table_names = [table[0].lower() for table in tables]
                conn.close()
                print(f"ðŸ”§ Debug: Downloaded database contains tables: {table_names}")
                print(f"ðŸ”§ Debug: Table count: {len(table_names)}")
            except Exception as e:
                print(f"âš ï¸  Warning: Could not verify downloaded database: {e}")
            
            return True
        else:
            print("âŒ Download succeeded but file doesn't exist locally")
            return False
    else:
        print(f"âŒ Failed to download database from {GCS_PATH}")
        print(f"âŒ Error details: {stderr}")
        print(f"âŒ Stdout: {stdout}")
        return False

def upload_to_gcs():
    """Upload local database to GCS"""
    if not GCS_PATH:
        print("âš ï¸  No GOOGLE_CLOUD_PROJECT set, skipping GCS upload")
        return False
    
    db_file = Path(DB_FILE)
    
    if not db_file.exists():
        print("âš ï¸  No local database to upload")
        return False
    
    size_mb = db_file.stat().st_size / (1024 * 1024)
    print(f"ðŸ“¤ Uploading database to {GCS_PATH} ({size_mb:.1f} MB)...")
    
    # Use -h flag to disable caching
    success, stdout, stderr = run_gsutil_command([
        "gsutil", "-h", "Cache-Control:no-cache, max-age=0", 
        "cp", DB_FILE, GCS_PATH
    ])
    
    if success:
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        print(f"âœ… Database uploaded successfully at {timestamp}")
        return True
    else:
        print(f"âŒ Failed to upload database: {stderr}")
        return False

def get_local_db_mtime():
    """Get last modified time of local database"""
    db_file = Path(DB_FILE)
    if db_file.exists():
        return db_file.stat().st_mtime
    return None

def periodic_upload_worker():
    """Background worker that periodically uploads database to GCS"""
    print(f"ðŸ”„ Starting periodic upload worker (interval: {SYNC_INTERVAL}s)")
    
    last_mtime = get_local_db_mtime()
    
    while True:
        try:
            time.sleep(SYNC_INTERVAL)
            
            current_mtime = get_local_db_mtime()
            
            # Only upload if file has been modified
            if current_mtime and current_mtime != last_mtime:
                print("ðŸ“ Database has been modified, uploading to GCS...")
                if upload_to_gcs():
                    last_mtime = current_mtime
            else:
                print("âœ“ Database unchanged, skipping upload")
                
        except KeyboardInterrupt:
            print("ðŸ›‘ Upload worker stopped")
            break
        except Exception as e:
            print(f"âŒ Error in upload worker: {e}")
            time.sleep(60)  # Wait a bit before retrying

def start_periodic_upload(daemon=True):
    """Start background thread for periodic uploads"""
    thread = threading.Thread(target=periodic_upload_worker, daemon=daemon)
    thread.start()
    return thread

def ensure_database_exists():
    """Ensure database exists and is valid, download from GCS if incomplete"""
    import duckdb
    
    print("ðŸ”§ Debug: Starting ensure_database_exists()")
    print(f"ðŸ”§ Debug: Looking for database at: {DB_FILE}")
    print(f"ðŸ”§ Debug: Current working directory: {os.getcwd()}")
    
    db_file = Path(DB_FILE)
    needs_download = False
    
    # Check if local database exists and is complete
    if not db_file.exists():
        print("ðŸ“¥ No local database found")
        needs_download = True
    else:
        size_mb = db_file.stat().st_size / (1024 * 1024)
        print(f"ðŸ”§ Debug: Local database found ({size_mb:.1f} MB)")
        
        # Validate database has required schema
        try:
            print("ðŸ”§ Debug: Connecting to database for validation...")
            conn = duckdb.connect(str(db_file))
            tables = conn.execute("SHOW TABLES").fetchall()
            table_names = [table[0].lower() for table in tables]
            conn.close()
            
            print(f"ðŸ”§ Debug: Database validation - found {len(tables)} tables")
            print(f"ðŸ”§ Debug: Table names: {table_names}")
            
            required_tables = ['bet_history', 'fixtures', 'odds', 'predictions']
            missing_tables = [table for table in required_tables if table not in table_names]
            
            if missing_tables:
                print(f"âš ï¸  Local database missing required tables: {missing_tables}")
                print(f"ðŸ“Š Available tables: {table_names}")
                print("ðŸ”„ Will replace incomplete database with complete version from GCS...")
                needs_download = True
            else:
                print(f"âœ… Local database is complete - Found tables: {table_names}")
                return True
                
        except Exception as e:
            print(f"âŒ Error validating local database: {e}")
            print("ðŸ”„ Will download fresh database from GCS...")
            needs_download = True
    
    # Download from GCS if needed (this will overwrite incomplete local file)
    if needs_download:
        print("ðŸ“¥ Downloading complete database from GCS...")
        if not download_from_gcs():
            print("âŒ CRITICAL: Could not download database from GCS")
            if db_file.exists():
                print("âš ï¸  Will use incomplete local database - workflow may create missing tables")
                return True
            else:
                print("âŒ No local database available - cannot start")
                return False
        
        # Validate the downloaded database
        try:
            print("ðŸ”§ Debug: Validating downloaded database...")
            conn = duckdb.connect(str(db_file))
            tables = conn.execute("SHOW TABLES").fetchall()
            table_names = [table[0].lower() for table in tables]
            conn.close()
            
            required_tables = ['bet_history', 'fixtures', 'odds', 'predictions']
            missing_tables = [table for table in required_tables if table not in table_names]
            
            if missing_tables:
                print(f"âš ï¸  Downloaded database still missing tables: {missing_tables}")
                print(f"ðŸ“Š Available tables: {table_names}")
                print("ðŸ“ Tables will be created by workflow on first run")
            else:
                print(f"âœ… Downloaded database validated successfully - Found tables: {table_names}")
            
            return True
            
        except Exception as e:
            print(f"âŒ CRITICAL: Downloaded database validation failed: {e}")
            return False
    
    return True
        
    except Exception as e:
        print(f"âŒ CRITICAL: Database validation failed: {e}")
        print("âŒ Database may be corrupted")
        return False

if __name__ == "__main__":
    import sys
    
    command = sys.argv[1] if len(sys.argv) > 1 else "setup"
    
    if command == "download":
        success = download_from_gcs()
        sys.exit(0 if success else 1)
    
    elif command == "upload":
        success = upload_to_gcs()
        sys.exit(0 if success else 1)
    
    elif command == "sync-loop":
        # Run continuous sync loop
        ensure_database_exists()
        periodic_upload_worker()
    
    elif command == "setup":
        # Initial setup (download or create)
        success = ensure_database_exists()
        sys.exit(0 if success else 1)
    
    else:
        print(f"Unknown command: {command}")
        print("Usage: python database_sync.py [download|upload|sync-loop|setup]")
        sys.exit(1)
